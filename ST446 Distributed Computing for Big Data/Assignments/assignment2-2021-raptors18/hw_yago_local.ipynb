{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ST446 Distributed Computing for Big Data\n",
        "## Assignment 2 - PART 1\n",
        "---\n",
        "\n",
        "*We highly recommend using GCP, as the data sets used are about 20 GB in total.* Alternatively, you can use your own computer.\n",
        "\n",
        "## P1: Querying the YAGO semantic knowledge base\n",
        "\n",
        "YAGO is a semantic knowledge base, derived from Wikipedia, WordNet and GeoNames. YAGO contains knowledge about more than 10 million entities (like persons, organizations and cities) and contains more than 120 million facts about these entities. You may find more about YAGO [here](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/#c10444).\n",
        "\n",
        "In this assignment, you are asked to use parts of the YAGO dataset to demonstrate your knowledge about Spark graphframes and motif queries. In particular, you are asked to **_use motif queries_** to find out answers to the following queries stated in English:\n",
        "\n",
        "**A (max points 5)**. _Politicians who are also scientists_ (sorted alphabetically by name of person)\n",
        "\n",
        "**B (max points 5)**. _Companies whose founders were born in London_ (sorted alphabetically by name of founder)\n",
        "\n",
        "**C (max points 5)**. _Writers who have won a Nobel Prize (in any discipline)_ (sorted alphabetically by name of person)\n",
        "\n",
        "**D (max points 5)**. _Nobel prize winners who were born in the same city as their spouses_ (sorted alphabetically by name of person)\n",
        "\n",
        "**E (max points 5)**. _Politicians that are affiliated with a right-wing party_ (sorted alphabetically by name of person)\n",
        "\n",
        "Please always show the first 20 entries of the resulting DataFrame and the total count of relevant entries."
      ],
      "metadata": {
        "id": "dIikFr7cAFkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### My cluster config\n",
        "```shell\n",
        "gcloud beta dataproc clusters create st446-mycluster \n",
        "    --properties=\"^#^spark:spark.jars.packages=graphframes:graphframes:0.5.0-spark2.1-s_2.11,com.databricks:spark-xml_2.11:0.4.1\" \n",
        "    --subnet default --enable-component-gateway \n",
        "    --region europe-west2 --zone europe-west2-c \n",
        "    --master-machine-type n1-standard-4 --master-boot-disk-size 500 \n",
        "    --num-workers 2 --worker-machine-type n1-standard-4 --worker-boot-disk-size 500 \n",
        "    --image-version 1.3-debian10 --optional-components ANACONDA,JUPYTER \n",
        "    --metadata \"PIP_PACKAGES=sklearn nltk pandas graphframes\" \n",
        "    --project st446-lse-2021 --bucket st446-mybucket\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 Get YAGO data\n",
        "\n",
        "You will need to download the following datasets that are part of YAGO (see [here](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/) for more information):\n",
        "\n",
        "* A set of relationships between instances (for example, specifying that Emomali Rahmon is the leader of the Military of Tajikistan). Link: http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoFacts.tsv.7z\n",
        "\n",
        "* A set of subclass relationships (for example, specifying that *A1086* is *a road in England*, or that *Salmonella Dub* is *a Reggae music group* and also a *New Zealand dub musical group*). Link: http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoTransitiveType.tsv.7z\n",
        "\n",
        "Please use `wget` to download the data to your compute engine (the files are big!).\n",
        "\n",
        "Next, you will need to extract `tsv` files from the `7z` archives that you have downloaded. Use the following commands to install `p7zip` on your compute engine and extract the files.\n",
        "```\n",
        "sudo apt-get install p7zip-full\n",
        "7z x yagoTransitiveType.tsv.7z \n",
        "7z x yagoFacts.tsv.7z \n",
        "```\n",
        "Please note that this can take a while, in particular as `yagoTransitiveType.tsv` is **18GB** large.\n",
        "\n",
        "Put the files (`yagoTransitiveType.tsv` and `yagoFacts.tsv`) into the Hadoop file system. \n",
        "Also, have a look at their first few lines to understand what kind of data they contain."
      ],
      "metadata": {
        "id": "fz6Fy6jfAFkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "**The command I used to download data and put data into hdfs**\n",
        "```\n",
        "wget http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoFacts.tsv.7z\n",
        "wget http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoTransitiveType.tsv.7z\n",
        "sudo apt-get install p7zip-full\n",
        "7z x yagoTransitiveType.tsv.7z \n",
        "7z x yagoFacts.tsv.7z\n",
        "hadoop fs -put ./ /yago\n",
        "```"
      ],
      "metadata": {
        "id": "I_oIUo4nAFks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 Read the data into a Spark DataFrame\n",
        "\n",
        "Please load the data from `yagoFacts.tsv` into a DataFrame called `df` and `yagoTransitiveType.tsv` into a DataFrame called `df_subclasses`.\n",
        "Have a look at the beginning of the files to understand the schema.\n",
        "Once imported, both DataFrames should have columns labelled as `id`, `subject`, `predicate`, `object` and `value`.\n",
        "In the case of `yagoTransitiveType.tsv`, some of the predicates can be understood as *\"is a sublcass of\"* or *\"is member of the class\"*, and the objects can be understood as classes."
      ],
      "metadata": {
        "id": "kPkTqjAFAFks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "# your code\n",
        "# define a schema for the dataframes\n",
        "schema_df = StructType([\n",
        "    StructField(\"id\", StringType()),\n",
        "    StructField(\"subject\", StringType()),\n",
        "    StructField(\"predicate\", StringType()),\n",
        "    StructField(\"object\", StringType()),\n",
        "    StructField(\"value\", DoubleType())])\n",
        "\n",
        "schema_df_sub = StructType([\n",
        "    StructField(\"id\", StringType()),\n",
        "    StructField(\"subject\", StringType()),\n",
        "    StructField(\"predicate\", StringType()),\n",
        "    StructField(\"object\", StringType()),\n",
        "    StructField(\"value\", DoubleType())])\n",
        "\n",
        "# create dataframe directly from the tsv file on HDFS\n",
        "df = spark.read.csv('/yago/yagoFacts.tsv', schema=schema_df, header='false', sep='\\t')\n",
        "df_subclasses = spark.read.csv('/yago/yagoTransitiveType.tsv', schema=schema_df_sub, header='false', sep='\\t')"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "id": "cJO_frZGAFkt",
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.3 Understand the database schema\n",
        "\n",
        "Let's look at the schema:"
      ],
      "metadata": {
        "id": "G5aQpS0hAFkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print the table schema\n",
        "df.printSchema()\n",
        "df_subclasses.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- subject: string (nullable = true)\n",
            " |-- predicate: string (nullable = true)\n",
            " |-- object: string (nullable = true)\n",
            " |-- value: double (nullable = true)\n",
            "\n",
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- subject: string (nullable = true)\n",
            " |-- predicate: string (nullable = true)\n",
            " |-- object: string (nullable = true)\n",
            " |-- value: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The useful information is in columns \"subject\", \"predicate\" and \"object\". \"predicate\" defines the relation between entities \"subject\" and \"object\". For example, for \"Albert Einstein was born in Ulm\", \"Albert Einstein\" is the subject, \"was born in\" is the predicate and \"Ulm\" is the object."
      ],
      "metadata": {
        "id": "ULK0aipvAFku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.4 Simple query example\n",
        "\n",
        "To get information about where Albert Einstein was born, we load data into Spark using the following query:"
      ],
      "metadata": {
        "id": "rWlhiNH8AFkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "born_city_df = df.where(\"predicate = '<wasBornIn>'\")\n",
        "born_city_df.show(1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----------+---------------+-----+\n",
            "|                  id|             subject|  predicate|         object|value|\n",
            "+--------------------+--------------------+-----------+---------------+-----+\n",
            "|<id_thPX9b1zg!_7f...|<William_Jones_(W...|<wasBornIn>|<Penrhiwceiber>| null|\n",
            "+--------------------+--------------------+-----------+---------------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "id": "SZiOTz8aAFkv",
        "outputId": "eebcd600-e82a-4de1-a356-b832a493306f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "born_city_df.where(\"subject = '<Albert_Einstein>'\").show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+-----------+------+-----+\n",
            "|                  id|          subject|  predicate|object|value|\n",
            "+--------------------+-----------------+-----------+------+-----+\n",
            "|<id_sbCVliqDT2_7f...|<Albert_Einstein>|<wasBornIn>| <Ulm>| null|\n",
            "+--------------------+-----------------+-----------+------+-----+\n",
            "\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "id": "gPKj9hu3AFkw",
        "outputId": "b5cf2fea-3c1e-456b-abb5-b48f5b48ef72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may wonder how one would know whether to use the predicate '&lt;wasBornIn&gt;' or '&lt;was_born_in&gt;' and subject '&lt;Albert_Einstein&gt;' or '&lt;AlbertEinstein&gt;'. For YAGO subjects (and objects), the naming is aligned with Wikipedia. For example, Albert Einstein's wiki is: https://en.wikipedia.org/wiki/Albert_Einstein and you can see it is 'Albert_Einstein'. \n",
        "\n",
        "For predicates, you can look at the \"property\" list from the [Yago Web interface](https://gate.d5.mpi-inf.mpg.de/webyagospotlx/WebInterface?L01=%3Fx&L0R=%3CwasBornIn%3E&L02=%3Fc&L0T=&L03=&L0L=&L04=&L05=&L11=&L1R=&L12=&L1T=&L13=&L1L=&L14=&L15=&L21=&L2R=&L22=&L2T=&L23=&L2L=&L24=&L25=&L31=&L3R=&L32=&L3T=&L33=&L3L=&L34=&L35=&L41=&L4R=&L42=&L4T=&L43=&L4L=&L44=&L45=). \n",
        "Try different queries with this web interface query to understand more how to query YAGO."
      ],
      "metadata": {
        "id": "k88MMFJ-AFkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.5 Simple motif example\n",
        "\n",
        "In this part of the assignment, you are required to use **motif** to find out answer to the 4 questions. Please complete the following example to find out: \"Which city was Albert Einstein born in?\" using motif queries instead of  SQL queries on the first dataframe (`df`):"
      ],
      "metadata": {
        "id": "5uLuSmGuAFkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from graphframes import *\n",
        "\n",
        "def vertices_edges_split(df, condition):\n",
        "    sub = df.filter(condition).select(\"subject\").withColumnRenamed(\"subject\",\"id\")\n",
        "    obj = df.filter(condition).select(\"object\").withColumnRenamed(\"object\",\"id\")\n",
        "    v = sub.union(obj).distinct()\n",
        "    e = df.filter(condition).select(\"subject\",\"object\",\"predicate\")\\\n",
        "    .withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\")\n",
        "    return v, e"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "hOmxi3b1AFkx",
        "outputId": "5adb3f26-5c02-410c-fc16-4d67d96c9eee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v, e = vertices_edges_split(df, \"subject='<Albert_Einstein>'\")\n",
        "g = GraphFrame(v, e)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "hOmxi3b1AFkx",
        "outputId": "5adb3f26-5c02-410c-fc16-4d67d96c9eee",
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code\n",
        "res = g.find(\"(a)-[e]->(b)\").filter(\"e.predicate = '<wasBornIn>'\")\n",
        "res.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.6 Some useful tips\n",
        "\n",
        "### Get a subset of YAGO database\n",
        "YAGO database is large, so we don't try to load the entire database into a dataframe and then query it. If you do this, you will find that you won't even be able to execute `df.take(1)`, as it would take up too much of space (at least on a laptop). Instead, you use Spark SQL commands or `df.where` to get a suitable fraction of the data.\n",
        "\n",
        "### Try the queries in the YAGO Web interface first\n",
        "It is sometimes tricky to get the right \"subject\", \"predicate\" and \"object\". It is easier if you start from [Yago Web interface](https://gate.d5.mpi-inf.mpg.de/webyagospotlx/WebInterface?L01=%3Fx&L0R=%3CwasBornIn%3E&L02=%3Fc&L0T=&L03=&L0L=&L04=&L05=&L11=&L1R=&L12=&L1T=&L13=&L1L=&L14=&L15=&L21=&L2R=&L22=&L2T=&L23=&L2L=&L24=&L25=&L31=&L3R=&L32=&L3T=&L33=&L3L=&L34=&L35=&L41=&L4R=&L42=&L4T=&L43=&L4L=&L44=&L45=) rather than directly querying in Pyspark. Once your query works, you can convert your query to Pyspark code. Note that sometimes the web version of object/subject code may be different from what you need to type here. For example, company code is &lt;wordnet_company_108058098&gt; when you do the query here but when you do it via the web interface it is &lt;wordnet company 108058098&gt;. \n",
        "\n",
        "### Be patient and don't do this exercise in the last minute\n",
        "Some trial and error is needed to get the query right and it may take some time get the result for a query. For these reasons, we advise you not to wait to work out this exercise just before the submission deadline. \n",
        "\n",
        "### Make sure to get the initialization actions right\n",
        "For this exercise, you will be using GraphFrames."
      ],
      "metadata": {
        "id": "wmd1E8UGAFkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Politicians who are also scientists (Question A)\n",
        "Find all politicians who are also scientists. Output top 20 of them. How many people are in the dataset who are both scientists and politicians?\n",
        "Please follow these steps:\n",
        "* Operate on the subsets of `df_subclasses` where the objects are `'<wordnet_scientist_110560637>` (scientists) and `'<wordnet_politician_110450303>'` (politicians), and where the predicates are `rdf:type`.\n",
        "* Use graphframes and the right parts of `df_subclasses` to construct a graph whose (directed) edges point from subjects to objects. Hence, its source vertices are subjects and it destination vertices are objects. It may be convenient to use intermediate DataFrames and join all the required dataframes of edges and vertices.\n",
        "* The subjects will be people and the objects will be classes (e.g., scientists, politicians).\n",
        "* Use a motif query to find all instances that fulfil the criteria specified in the question.\n",
        "* It is a good idea to define a function that takes a DataFrame and outputs a set of data frames for vertices and edges.\n",
        "\n",
        "Please sort the output alphabetically by the person column."
      ],
      "metadata": {
        "id": "dcG2wA0eAFky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "#### My solutions\n",
        "A main challenge (for each part) besides the motiv query is to first find a suitable subset of the Yago data to create a graph, which can then be processed using the motiv queries. This subset should not be too large because that would lead to a very long processing time for the motiv query requires.\n",
        "\n",
        "For this first question, the subset I use includes:\n",
        "- all scientists, and\n",
        "- all politians, \n",
        "\n",
        "as well as the information about all the relationships which stored in the edges (who is a scientist and who is a politian)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# define condiions\n",
        "condition1 = \"object='<wordnet_scientist_110560637>'\"\n",
        "condition2 = \"object='<wordnet_politician_110450303>'\"\n",
        "\n",
        "# create graph\n",
        "v1, e1 = vertices_edges_split(df_subclasses, condition1)\n",
        "v2, e2 = vertices_edges_split(df_subclasses, condition2)\n",
        "\n",
        "v = v1.union(v2).distinct()\n",
        "e = e1.union(e2).distinct()\n",
        "g = GraphFrame(v, e)\n",
        "\n",
        "# define motiv query\n",
        "res = g.find(\"(a)-[e1]->(b); (a)-[e2]->(c)\").filter(\"b.id < c.id\")"
      ],
      "outputs": [],
      "execution_count": 64,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res.orderBy(\"a\").distinct().show(20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                   a|                  e1|                   b|                  e2|                   c|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      [<A._C._Cuza>]|[<A._C._Cuza>, <w...|[<wordnet_politic...|[<A._C._Cuza>, <w...|[<wordnet_scienti...|\n",
            "|[<A._P._J._Abdul_...|[<A._P._J._Abdul_...|[<wordnet_politic...|[<A._P._J._Abdul_...|[<wordnet_scienti...|\n",
            "|       [<Aad_Kosto>]|[<Aad_Kosto>, <wo...|[<wordnet_politic...|[<Aad_Kosto>, <wo...|[<wordnet_scienti...|\n",
            "|        [<Aad_Nuis>]|[<Aad_Nuis>, <wor...|[<wordnet_politic...|[<Aad_Nuis>, <wor...|[<wordnet_scienti...|\n",
            "| [<Aaron_Aaronsohn>]|[<Aaron_Aaronsohn...|[<wordnet_politic...|[<Aaron_Aaronsohn...|[<wordnet_scienti...|\n",
            "|  [<Aaron_Farrugia>]|[<Aaron_Farrugia>...|[<wordnet_politic...|[<Aaron_Farrugia>...|[<wordnet_scienti...|\n",
            "|        [<Ab_Klink>]|[<Ab_Klink>, <wor...|[<wordnet_politic...|[<Ab_Klink>, <wor...|[<wordnet_scienti...|\n",
            "|  [<Abba_P._Lerner>]|[<Abba_P._Lerner>...|[<wordnet_politic...|[<Abba_P._Lerner>...|[<wordnet_scienti...|\n",
            "|[<Abbas_Ahmad_Akh...|[<Abbas_Ahmad_Akh...|[<wordnet_politic...|[<Abbas_Ahmad_Akh...|[<wordnet_scienti...|\n",
            "|   [<Abbie_Hoffman>]|[<Abbie_Hoffman>,...|[<wordnet_politic...|[<Abbie_Hoffman>,...|[<wordnet_scienti...|\n",
            "|[<Abbott_Lawrence...|[<Abbott_Lawrence...|[<wordnet_politic...|[<Abbott_Lawrence...|[<wordnet_scienti...|\n",
            "|[<Abdallah_Salem_...|[<Abdallah_Salem_...|[<wordnet_politic...|[<Abdallah_Salem_...|[<wordnet_scienti...|\n",
            "|[<Abdelbaki_Herma...|[<Abdelbaki_Herma...|[<wordnet_politic...|[<Abdelbaki_Herma...|[<wordnet_scienti...|\n",
            "| [<Abdellatif_Abid>]|[<Abdellatif_Abid...|[<wordnet_politic...|[<Abdellatif_Abid...|[<wordnet_scienti...|\n",
            "|[<Abdelouahed_Sou...|[<Abdelouahed_Sou...|[<wordnet_politic...|[<Abdelouahed_Sou...|[<wordnet_scienti...|\n",
            "| [<Abdelwahed_Radi>]|[<Abdelwahed_Radi...|[<wordnet_politic...|[<Abdelwahed_Radi...|[<wordnet_scienti...|\n",
            "|[<Abdesslam_Yassi...|[<Abdesslam_Yassi...|[<wordnet_politic...|[<Abdesslam_Yassi...|[<wordnet_scienti...|\n",
            "|[<Abdi_Farah_Shir...|[<Abdi_Farah_Shir...|[<wordnet_politic...|[<Abdi_Farah_Shir...|[<wordnet_scienti...|\n",
            "|[<Abdirahman_Dual...|[<Abdirahman_Dual...|[<wordnet_politic...|[<Abdirahman_Dual...|[<wordnet_scienti...|\n",
            "|[<Abdiweli_Mohame...|[<Abdiweli_Mohame...|[<wordnet_politic...|[<Abdiweli_Mohame...|[<wordnet_scienti...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "CPU times: user 130 ms, sys: 52 ms, total: 182 ms\n",
            "Wall time: 11min 2s\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res.count()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 144 ms, sys: 21.8 ms, total: 166 ms\n",
            "Wall time: 10min 36s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 66,
          "data": {
            "text/plain": "7182"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The total number of politicians that are also scientists is: 7182"
      ],
      "metadata": {
        "id": "83ldod3AAFk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Companies whose founders were born in London (Question B)\n",
        "For companies, use `'<wordnet_company_108058098>'`. \n",
        "For *\"being founder\"*, use `<created>`.\n",
        "\n",
        "By now, you will understand which DataFrame to use for what. \n",
        "\n",
        "Set up a graph and use a motif query to find companies whose founders were born in London.\n",
        "Please take some time to figure out how a suitable configuration of nodes and edges should look like.  How many such companies are there in our dataset?\n",
        "\n",
        "Please sort the output alphabetically by the founder column."
      ],
      "metadata": {
        "id": "7wEOj9sJAFk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The subset used for this part consists of:\n",
        "- all companies,\n",
        "- all founders and their companies, and\n",
        "- all people born in London,\n",
        "\n",
        "as well as, again, all relationships that are present in the subset of the data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# define condiions\n",
        "condition1 = \"object='<wordnet_company_108058098>'\"\n",
        "condition2 = \"predicate='<created>'\"\n",
        "condition3 = \"predicate='<wasBornIn>' AND object='<London>'\"\n",
        "\n",
        "# create graph\n",
        "v1, e1 = vertices_edges_split(df_subclasses, condition1)\n",
        "v2, e2 = vertices_edges_split(df, condition2)\n",
        "v3, e3 = vertices_edges_split(df, condition3)\n",
        "\n",
        "v = v1.union(v2).union(v3).distinct()\n",
        "e = e1.union(e2).union(e3).distinct()\n",
        "g = GraphFrame(v, e)\n",
        "\n",
        "# define motiv query\n",
        "res = g.find(\"(company)-[e1]->(wordnet);(founder)-[e2]->(company);(founder)-[e3]->(city)\")\\\n",
        "       .filter(\"e1.dst='<wordnet_company_108058098>'\")\\\n",
        "       .filter(\"e2.predicate='<created>'\")\\\n",
        "       .filter(\"e3.dst='<London>'\")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res.orderBy(\"founder\").show(20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|             company|                  e1|             wordnet|             founder|                  e2|                  e3|      city|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|     [<Dare_Comics>]|[<Dare_Comics>, <...|[<wordnet_company...|      [<Adam_Hamdy>]|[<Adam_Hamdy>, <D...|[<Adam_Hamdy>, <L...|[<London>]|\n",
            "|[<Jawbone_(compan...|[<Jawbone_(compan...|[<wordnet_company...|[<Alexander_Assei...|[<Alexander_Assei...|[<Alexander_Assei...|[<London>]|\n",
            "|      [<Video_Arts>]|[<Video_Arts>, <w...|[<wordnet_company...|      [<Antony_Jay>]|[<Antony_Jay>, <V...|[<Antony_Jay>, <L...|[<London>]|\n",
            "|[<SENS_Research_F...|[<SENS_Research_F...|[<wordnet_company...|  [<Aubrey_de_Grey>]|[<Aubrey_de_Grey>...|[<Aubrey_de_Grey>...|[<London>]|\n",
            "|[<Andreessen_Horo...|[<Andreessen_Horo...|[<wordnet_company...|    [<Ben_Horowitz>]|[<Ben_Horowitz>, ...|[<Ben_Horowitz>, ...|[<London>]|\n",
            "|  [<LO-MAX_Records>]|[<LO-MAX_Records>...|[<wordnet_company...|[<Bernard_MacMaho...|[<Bernard_MacMaho...|[<Bernard_MacMaho...|[<London>]|\n",
            "|        [<PowerBar>]|[<PowerBar>, <wor...|[<wordnet_company...|   [<Brian_Maxwell>]|[<Brian_Maxwell>,...|[<Brian_Maxwell>,...|[<London>]|\n",
            "|[<Primrose_Hill_P...|[<Primrose_Hill_P...|[<wordnet_company...|    [<Bruno_Heller>]|[<Bruno_Heller>, ...|[<Bruno_Heller>, ...|[<London>]|\n",
            "|  [<United_Artists>]|[<United_Artists>...|[<wordnet_company...| [<Charlie_Chaplin>]|[<Charlie_Chaplin...|[<Charlie_Chaplin...|[<London>]|\n",
            "|[<Kurrupt_Recordi...|[<Kurrupt_Recordi...|[<wordnet_company...|       [<Dan_Joyce>]|[<Dan_Joyce>, <Ku...|[<Dan_Joyce>, <Lo...|[<London>]|\n",
            "|[<Three_Rings_Des...|[<Three_Rings_Des...|[<wordnet_company...|[<Daniel_James_(g...|[<Daniel_James_(g...|[<Daniel_James_(g...|[<London>]|\n",
            "|         [<I-Logix>]|[<I-Logix>, <word...|[<wordnet_company...|     [<David_Harel>]|[<David_Harel>, <...|[<David_Harel>, <...|[<London>]|\n",
            "|    [<Heyday_Films>]|[<Heyday_Films>, ...|[<wordnet_company...|    [<David_Heyman>]|[<David_Heyman>, ...|[<David_Heyman>, ...|[<London>]|\n",
            "|[<Israel_Council_...|[<Israel_Council_...|[<wordnet_company...|    [<David_Kimche>]|[<David_Kimche>, ...|[<David_Kimche>, ...|[<London>]|\n",
            "|        [<DeepMind>]|[<DeepMind>, <wor...|[<wordnet_company...|  [<Demis_Hassabis>]|[<Demis_Hassabis>...|[<Demis_Hassabis>...|[<London>]|\n",
            "|  [<Scripps_Health>]|[<Scripps_Health>...|[<wordnet_company...|[<Ellen_Browning_...|[<Ellen_Browning_...|[<Ellen_Browning_...|[<London>]|\n",
            "|[<Luce,_Forward,_...|[<Luce,_Forward,_...|[<wordnet_company...|[<Ellen_Browning_...|[<Ellen_Browning_...|[<Ellen_Browning_...|[<London>]|\n",
            "| [<Blossöm_Records>]|[<Blossöm_Records...|[<wordnet_company...|    [<Elliot_James>]|[<Elliot_James>, ...|[<Elliot_James>, ...|[<London>]|\n",
            "|    [<Syncopy_Inc.>]|[<Syncopy_Inc.>, ...|[<wordnet_company...|     [<Emma_Thomas>]|[<Emma_Thomas>, <...|[<Emma_Thomas>, <...|[<London>]|\n",
            "|[<Rezolution_Pict...|[<Rezolution_Pict...|[<wordnet_company...|     [<Ernest_Webb>]|[<Ernest_Webb>, <...|[<Ernest_Webb>, <...|[<London>]|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "CPU times: user 443 ms, sys: 127 ms, total: 570 ms\n",
            "Wall time: 34min 38s\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are only 59 different companies, but 61 entries"
      ],
      "metadata": {
        "id": "LW1xpb2QAFk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# show count of distinct companies\n",
        "res.select(\"company\").distinct().count()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 146 ms, sys: 52.6 ms, total: 199 ms\n",
            "Wall time: 12min 17s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "59"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "nLA5KFv7AFk1",
        "outputId": "a864c806-8005-41c3-d431-282a06bf637f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res.count()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 124 ms, sys: 45.3 ms, total: 169 ms\n",
            "Wall time: 10min 32s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "61"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "KnVRNhhwAFk1",
        "outputId": "b52ce9be-5a58-4efb-fc46-f9e3414490f1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Writers who have won a Nobel Prize in any discipline, including economics (Question C)\n",
        "Tags for nobel prizes look like these: `'<Nobel_Prize_in_Chemistry>`, `<Nobel_Prize_in_Physics>'`, `<Nobel_Prize>` or `<Nobel_Prize>` etc.\n",
        "We are also counting this one: `'<Nobel_Memorial_Prize_in_Economic_Sciences>'`.\n",
        "\n",
        "The tag for writers is `'<wordnet_writer_110794014>'`.\n",
        "\n",
        "You will need to use `'<hasWonPrize>'` as a predicate.\n",
        "\n",
        "Please sort the output alphabetically by the person column."
      ],
      "metadata": {
        "id": "ZEoKKWjTAFk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subset includes:\n",
        "- all writers, and\n",
        "- all people who have one any of the Nobel Prizes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# all nobel prices\n",
        "prizes = \"\"\"('<Nobel_Prize_in_Chemistry>','<Nobel_Prize_in_Physics>','<Nobel_Prize>',\\\n",
        "            '<Nobel_Memorial_Prize_in_Economic_Sciences>','<Nobel_Peace_Prize>',\\\n",
        "            '<Nobel_Prize_in_Physiology_or_Medicine>','<Nobel_Prize_in_Literature>')\"\"\"\n",
        "\n",
        "# define conditions\n",
        "condition1 = \"object='<wordnet_writer_110794014>'\"\n",
        "condition2 = \"predicate='<hasWonPrize>' AND object IN {}\".format(prizes)\n",
        "\n",
        "# create graph\n",
        "v1, e1 = vertices_edges_split(df_subclasses, condition1)\n",
        "v2, e2 = vertices_edges_split(df, condition2)\n",
        "\n",
        "v = v1.union(v2).distinct()\n",
        "e = e1.union(e2).distinct()\n",
        "g = GraphFrame(v, e)\n",
        "\n",
        "# define motiv query\n",
        "res = g.find(\"(writer)-[e1]->(price); (writer)-[e2]->(type)\")\\\n",
        "       .filter(\"e1.predicate='<hasWonPrize>' AND e2.dst='<wordnet_writer_110794014>'\")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "res.orderBy(\"writer\").show(20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|              writer|                  e1|               price|                  e2|                type|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| [<14th_Dalai_Lama>]|[<14th_Dalai_Lama...|[<Nobel_Peace_Pri...|[<14th_Dalai_Lama...|[<wordnet_writer_...|\n",
            "|[<Adrienne_Clarks...|[<Adrienne_Clarks...|[<Nobel_Prize_in_...|[<Adrienne_Clarks...|[<wordnet_writer_...|\n",
            "|         [<Al_Gore>]|[<Al_Gore>, <Nobe...|[<Nobel_Peace_Pri...|[<Al_Gore>, <word...|[<wordnet_writer_...|\n",
            "|    [<Albert_Camus>]|[<Albert_Camus>, ...|[<Nobel_Prize_in_...|[<Albert_Camus>, ...|[<wordnet_writer_...|\n",
            "| [<Albert_Einstein>]|[<Albert_Einstein...|[<Nobel_Prize_in_...|[<Albert_Einstein...|[<wordnet_writer_...|\n",
            "|   [<Albert_Lutuli>]|[<Albert_Lutuli>,...|[<Nobel_Peace_Pri...|[<Albert_Lutuli>,...|[<wordnet_writer_...|\n",
            "|[<Albert_Schweitz...|[<Albert_Schweitz...|[<Nobel_Peace_Pri...|[<Albert_Schweitz...|[<wordnet_writer_...|\n",
            "|[<Aleksandr_Solzh...|[<Aleksandr_Solzh...|[<Nobel_Prize_in_...|[<Aleksandr_Solzh...|[<wordnet_writer_...|\n",
            "|[<Alexander_Prokh...|[<Alexander_Prokh...|[<Nobel_Prize_in_...|[<Alexander_Prokh...|[<wordnet_writer_...|\n",
            "|[<Alexei_Alexeyev...|[<Alexei_Alexeyev...|[<Nobel_Prize_in_...|[<Alexei_Alexeyev...|[<wordnet_writer_...|\n",
            "|   [<Alexis_Carrel>]|[<Alexis_Carrel>,...|[<Nobel_Prize_in_...|[<Alexis_Carrel>,...|[<wordnet_writer_...|\n",
            "|[<Alfonso_García_...|[<Alfonso_García_...|[<Nobel_Peace_Pri...|[<Alfonso_García_...|[<wordnet_writer_...|\n",
            "|[<Alfred_Hermann_...|[<Alfred_Hermann_...|[<Nobel_Peace_Pri...|[<Alfred_Hermann_...|[<wordnet_writer_...|\n",
            "|  [<Alfred_Kastler>]|[<Alfred_Kastler>...|[<Nobel_Prize_in_...|[<Alfred_Kastler>...|[<wordnet_writer_...|\n",
            "|     [<Alice_Munro>]|[<Alice_Munro>, <...|[<Nobel_Prize_in_...|[<Alice_Munro>, <...|[<wordnet_writer_...|\n",
            "|     [<Alva_Myrdal>]|[<Alva_Myrdal>, <...|[<Nobel_Peace_Pri...|[<Alva_Myrdal>, <...|[<wordnet_writer_...|\n",
            "|   [<Alvin_E._Roth>]|[<Alvin_E._Roth>,...|[<Nobel_Memorial_...|[<Alvin_E._Roth>,...|[<wordnet_writer_...|\n",
            "|   [<Alvin_Toffler>]|[<Alvin_Toffler>,...|[<Nobel_Prize_in_...|[<Alvin_Toffler>,...|[<wordnet_writer_...|\n",
            "|     [<Amartya_Sen>]|[<Amartya_Sen>, <...|[<Nobel_Memorial_...|[<Amartya_Sen>, <...|[<wordnet_writer_...|\n",
            "|  [<Anatole_France>]|[<Anatole_France>...|[<Nobel_Prize_in_...|[<Anatole_France>...|[<wordnet_writer_...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "CPU times: user 151 ms, sys: 52.4 ms, total: 203 ms\n",
            "Wall time: 14min 18s\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res.count()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 68.5 ms, sys: 38.7 ms, total: 107 ms\n",
            "Wall time: 7min 47s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "260"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "gr6VDYS_AFk2",
        "outputId": "c327bd7a-13cb-4f7f-927c-885a4e89cbaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Nobel prize winners who were born in the same city as their spouses (Question D)\n",
        "You may find the predicate `'<isMarriedTo>'` useful to create a Dataframe of all mariages.\n",
        "Please also show the cities in which the Nobel laureates and their spouses were born.\n",
        "\n",
        "Please sort the output alphabetically by the person (prize winner) column."
      ],
      "metadata": {
        "id": "4OZpUAkkAFk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In short, the yago subset includes:\n",
        "- all Nobel Price winners (any price),\n",
        "- all marriages, and\n",
        "- all birth information."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# define condistions\n",
        "condition1 = \"predicate='<hasWonPrize>' AND object in {}\".format(prizes)\n",
        "condition2 = \"predicate='<isMarriedTo>'\"\n",
        "condition3 = \"predicate='<wasBornIn>'\"\n",
        "\n",
        "# create graph\n",
        "v1, e1 = vertices_edges_split(df, condition1)\n",
        "v2, e2 = vertices_edges_split(df, condition2)\n",
        "v3, e3 = vertices_edges_split(df, condition3)\n",
        "\n",
        "v = v1.union(v2).union(v3).distinct()\n",
        "e = e1.union(e2).union(e3).distinct()\n",
        "\n",
        "g = GraphFrame(v, e)\n",
        "\n",
        "res = g.find(\"(winner)-[e1]->(price); (winner)-[e2]->(spouse); (winner)-[e3]->(city); (spouse)-[e4]->(city)\")\\\n",
        "       .filter(\"\"\"e1.predicate='<hasWonPrize>' AND \n",
        "               e2.predicate='<isMarriedTo>' AND \n",
        "               e3.predicate='<wasBornIn>' AND\n",
        "               e4.predicate='<wasBornIn>'\"\"\")"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res.orderBy(\"winner\").show(20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|              winner|                  e1|               price|                  e2|              spouse|                  e3|                city|                  e4|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|         [<Al_Gore>]|[<Al_Gore>, <Nobe...|[<Nobel_Peace_Pri...|[<Al_Gore>, <Tipp...|     [<Tipper_Gore>]|[<Al_Gore>, <Wash...|[<Washington,_D.C.>]|[<Tipper_Gore>, <...|\n",
            "|[<Carl_Ferdinand_...|[<Carl_Ferdinand_...|[<Nobel_Prize_in_...|[<Carl_Ferdinand_...|      [<Gerty_Cori>]|[<Carl_Ferdinand_...|          [<Prague>]|[<Gerty_Cori>, <P...|\n",
            "| [<Fridtjof_Nansen>]|[<Fridtjof_Nansen...|[<Nobel_Peace_Pri...|[<Fridtjof_Nansen...|      [<Eva_Nansen>]|[<Fridtjof_Nansen...|            [<Oslo>]|[<Eva_Nansen>, <O...|\n",
            "|[<Frédéric_Joliot...|[<Frédéric_Joliot...|[<Nobel_Prize_in_...|[<Frédéric_Joliot...|[<Irène_Joliot-Cu...|[<Frédéric_Joliot...|           [<Paris>]|[<Irène_Joliot-Cu...|\n",
            "|      [<Gerty_Cori>]|[<Gerty_Cori>, <N...|[<Nobel_Prize_in_...|[<Gerty_Cori>, <C...|[<Carl_Ferdinand_...|[<Gerty_Cori>, <P...|          [<Prague>]|[<Carl_Ferdinand_...|\n",
            "|[<Irène_Joliot-Cu...|[<Irène_Joliot-Cu...|[<Nobel_Prize_in_...|[<Irène_Joliot-Cu...|[<Frédéric_Joliot...|[<Irène_Joliot-Cu...|           [<Paris>]|[<Frédéric_Joliot...|\n",
            "|    [<Jimmy_Carter>]|[<Jimmy_Carter>, ...|[<Nobel_Peace_Pri...|[<Jimmy_Carter>, ...| [<Rosalynn_Carter>]|[<Jimmy_Carter>, ...| [<Plains,_Georgia>]|[<Rosalynn_Carter...|\n",
            "|[<Robert_Hofstadt...|[<Robert_Hofstadt...|[<Nobel_Prize_in_...|[<Robert_Hofstadt...|[<Douglas_Hofstad...|[<Robert_Hofstadt...|   [<New_York_City>]|[<Douglas_Hofstad...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n",
            "CPU times: user 116 ms, sys: 10.8 ms, total: 127 ms\n",
            "Wall time: 8min 44s\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res.count()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 26.8 ms, sys: 7.78 ms, total: 34.6 ms\n",
            "Wall time: 2min 3s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "8"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "id": "8HwjPO99AFk3",
        "outputId": "269c1666-4cfa-40da-e1bd-f65378f48a37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Politicians that are affiliated with a right-wing party (Question E)\n",
        "\n",
        "We are looking for all connections of the form `polician -> party`, where party is a right-wing party and politicians are defined above. If one politician is associated with several right wing parties, you may count them several times.\n",
        "\n",
        "Use `'<isAffiliatedTo>'` to find membership in organisations and `'<wikicat_Right-wing_parties>'` for right-wing parties organisations.\n",
        "\n",
        "There are multiple ways to do this.\n",
        "\n",
        "Please sort the output alphabetically by the person (politician) column."
      ],
      "metadata": {
        "id": "naDOrDAVAFk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The subset includes:\n",
        "- all politians,\n",
        "- all affiliations, and\n",
        "- all right-wing parties."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# define conditions\n",
        "condition1 = \"object='<wordnet_politician_110450303>'\"\n",
        "condition2 = \"predicate='<isAffiliatedTo>'\"\n",
        "condition3 = \"predicate='rdf:type' AND object='<wikicat_Right-wing_parties>'\"\n",
        "\n",
        "# create graph\n",
        "v1, e1 = vertices_edges_split(df_subclasses, condition1)\n",
        "v2, e2 = vertices_edges_split(df, condition2)\n",
        "v3, e3 = vertices_edges_split(df_subclasses, condition3)\n",
        "\n",
        "v = v1.union(v2).union(v3).distinct()\n",
        "e = e1.union(e2).union(e3).distinct()\n",
        "g = GraphFrame(v, e)\n",
        "\n",
        "# define motiv query\n",
        "res = g.find(\"(a)-[e1]->(b); (a)-[e2]->(c); (c)-[e3]->(e)\")\\\n",
        "       .filter(\"e1.predicate='rdf:type' AND e1.dst='<wordnet_politician_110450303>'\")\\\n",
        "       .filter(\"e2.predicate='<isAffiliatedTo>'\")\\\n",
        "       .filter(\"e3.dst='<wikicat_Right-wing_parties>'\")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res.orderBy(\"a\").show(20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                   a|                  e1|                   b|                  e2|                   c|                  e3|                   e|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|[<A.N.M._Ehsanul_...|[<A.N.M._Ehsanul_...|[<wordnet_politic...|[<A.N.M._Ehsanul_...|[<Bangladesh_Nati...|[<Bangladesh_Nati...|[<wikicat_Right-w...|\n",
            "|[<A._A._Wijethunga>]|[<A._A._Wijethung...|[<wordnet_politic...|[<A._A._Wijethung...|[<United_National...|[<United_National...|[<wikicat_Right-w...|\n",
            "|    [<A._B._Colton>]|[<A._B._Colton>, ...|[<wordnet_politic...|[<A._B._Colton>, ...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "|   [<A._C._Clemons>]|[<A._C._Clemons>,...|[<wordnet_politic...|[<A._C._Clemons>,...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "|     [<A._C._Gibbs>]|[<A._C._Gibbs>, <...|[<wordnet_politic...|[<A._C._Gibbs>, <...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "|    [<A._C._Hamlin>]|[<A._C._Hamlin>, ...|[<wordnet_politic...|[<A._C._Hamlin>, ...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "|[<A._Clifford_Jon...|[<A._Clifford_Jon...|[<wordnet_politic...|[<A._Clifford_Jon...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "|   [<A._Dean_Jeffs>]|[<A._Dean_Jeffs>,...|[<wordnet_politic...|[<A._Dean_Jeffs>,...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "|[<A._F._M._Ahsanu...|[<A._F._M._Ahsanu...|[<wordnet_politic...|[<A._F._M._Ahsanu...|[<Jatiya_Party_(E...|[<Jatiya_Party_(E...|[<wikicat_Right-w...|\n",
            "|     [<A._G._Crowe>]|[<A._G._Crowe>, <...|[<wordnet_politic...|[<A._G._Crowe>, <...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "|[<A._Homer_Byingt...|[<A._Homer_Byingt...|[<wordnet_politic...|[<A._Homer_Byingt...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "|[<A._Homer_Byingt...|[<A._Homer_Byingt...|[<wordnet_politic...|[<A._Homer_Byingt...|[<National_Union_...|[<National_Union_...|[<wikicat_Right-w...|\n",
            "|[<A._J._M._Muzamm...|[<A._J._M._Muzamm...|[<wordnet_politic...|[<A._J._M._Muzamm...|[<United_National...|[<United_National...|[<wikicat_Right-w...|\n",
            "|  [<A._J._McNamara>]|[<A._J._McNamara>...|[<wordnet_politic...|[<A._J._McNamara>...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "|[<A._J._Ranasinghe>]|[<A._J._Ranasingh...|[<wordnet_politic...|[<A._J._Ranasingh...|[<United_National...|[<United_National...|[<wikicat_Right-w...|\n",
            "|[<A._K._A._Firoze...|[<A._K._A._Firoze...|[<wordnet_politic...|[<A._K._A._Firoze...|[<Bangladesh_Nati...|[<Bangladesh_Nati...|[<wikicat_Right-w...|\n",
            "|     [<A._K._Patel>]|[<A._K._Patel>, <...|[<wordnet_politic...|[<A._K._Patel>, <...|[<Bharatiya_Janat...|[<Bharatiya_Janat...|[<wikicat_Right-w...|\n",
            "|[<A._Linwood_Holt...|[<A._Linwood_Holt...|[<wordnet_politic...|[<A._Linwood_Holt...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "|     [<A._M._Starr>]|[<A._M._Starr>, <...|[<wordnet_politic...|[<A._M._Starr>, <...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "| [<A._Piatt_Andrew>]|[<A._Piatt_Andrew...|[<wordnet_politic...|[<A._Piatt_Andrew...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "CPU times: user 221 ms, sys: 36.5 ms, total: 257 ms\n",
            "Wall time: 17min 54s\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res.count()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 220 ms, sys: 72.5 ms, total: 293 ms\n",
            "Wall time: 18min 38s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "32243"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "8HwjPO99AFk3",
        "outputId": "269c1666-4cfa-40da-e1bd-f65378f48a37",
        "scrolled": true
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [],
      "name": "hw_yago_local.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}